{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mia-khan/DS5110/blob/MiniProject/DS_5110_Mini_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HR8XGdrESED",
        "outputId": "14798a87-11b6-4add-d2a8-e23f208392b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset: cynthiarempel/amazon-us-customer-reviews-dataset\n",
            "Resuming download from 53477376 bytes (22444254373 bytes left)...\n",
            "Resuming download from https://www.kaggle.com/api/v1/datasets/download/cynthiarempel/amazon-us-customer-reviews-dataset?dataset_version_number=9 (53477376/22497731749) bytes left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.0G/21.0G [17:10<00:00, 21.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/cynthiarempel/amazon-us-customer-reviews-dataset/versions/9\n",
            "Files in the dataset directory: ['amazon_reviews_us_Major_Appliances_v1_00.tsv', 'amazon_reviews_us_Digital_Video_Games_v1_00.tsv', 'amazon_reviews_us_Video_Games_v1_00.tsv', 'amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv', 'amazon_reviews_us_Wireless_v1_00.tsv', 'amazon_reviews_us_Camera_v1_00.tsv', 'amazon_reviews_us_Video_v1_00.tsv', 'amazon_reviews_us_Software_v1_00.tsv', 'amazon_reviews_us_Digital_Video_Download_v1_00.tsv', 'amazon_reviews_us_Office_Products_v1_00.tsv', 'amazon_reviews_us_Grocery_v1_00.tsv', 'amazon_reviews_us_Tools_v1_00.tsv', 'amazon_reviews_multilingual_US_v1_00.tsv', 'amazon_reviews_us_Watches_v1_00.tsv', 'amazon_reviews_us_Sports_v1_00.tsv', 'amazon_reviews_us_Apparel_v1_00.tsv', 'amazon_reviews_us_Baby_v1_00.tsv', 'amazon_reviews_us_Electronics_v1_00.tsv', 'amazon_reviews_us_Pet_Products_v1_00.tsv', 'amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv', 'amazon_reviews_us_Toys_v1_00.tsv', 'amazon_reviews_us_Health_Personal_Care_v1_00.tsv', 'amazon_reviews_us_Shoes_v1_00.tsv', 'amazon_reviews_us_Automotive_v1_00.tsv', 'amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv', 'amazon_reviews_us_Books_v1_02.tsv', 'amazon_reviews_us_Furniture_v1_00.tsv', 'amazon_reviews_us_Music_v1_00.tsv', 'amazon_reviews_us_Gift_Card_v1_00.tsv', 'amazon_reviews_us_Beauty_v1_00.tsv', 'amazon_reviews_us_Musical_Instruments_v1_00.tsv', 'amazon_reviews_us_Mobile_Electronics_v1_00.tsv', 'amazon_reviews_us_Video_DVD_v1_00.tsv', 'amazon_reviews_us_PC_v1_00.tsv', 'amazon_reviews_us_Mobile_Apps_v1_00.tsv', 'amazon_reviews_us_Outdoors_v1_00.tsv', 'amazon_reviews_us_Digital_Software_v1_00.tsv']\n",
            "Reading TSV file: amazon_reviews_us_Major_Appliances_v1_00.tsv\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   16199106|R203HPW78Z7N4K|B0067WNSZY|     633038551|FGGF3032MW Galler...|Major Appliances|          5|            0|          0|   N|                Y|If you need a new...|What a great stov...| 2015-08-31|\n",
            "|         US|   16374060|R2EAIGVLEALSP3|B002QSXK60|     811766671|Best Hand Clothes...|Major Appliances|          5|            1|          1|   N|                Y|          Five Stars|        worked great| 2015-08-31|\n",
            "|         US|   15322085|R1K1CD73HHLILA|B00EC452R6|     345562728|Supco SET184 Ther...|Major Appliances|          5|            0|          0|   N|                Y|       Fast Shipping|Part exactly what...| 2015-08-31|\n",
            "|         US|   32004835|R2KZBMOFRMYOPO|B00MVVIF2G|     563052763|Midea WHS-160RB1 ...|Major Appliances|          5|            1|          1|   N|                Y|          Five Stars|Love my refrigera...| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "\n",
        "\n",
        "# Data Loading and Setup\n",
        "#=========================================================================================\n",
        "\n",
        "# Step 1: Download the dataset using kagglehub\n",
        "dataset_handle = \"cynthiarempel/amazon-us-customer-reviews-dataset\"\n",
        "print(f\"Downloading dataset: {dataset_handle}\")\n",
        "dataset_path = kagglehub.dataset_download(dataset_handle)\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "#=========================================================================================\n",
        "# Step 2: Initialize PySpark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Amazon Customer Reviews Analysis\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .getOrCreate()\n",
        "#=========================================================================================\n",
        "# Step 3: List all files in the dataset directory\n",
        "\n",
        "try:\n",
        "    files = os.listdir(dataset_path)\n",
        "    print(\"Files in the dataset directory:\", files)\n",
        "#=========================================================================================\n",
        "    # Step 4: Process each TSV file\n",
        "    for file in files:\n",
        "        if file.endswith(\".tsv\"):\n",
        "            file_path = os.path.join(dataset_path, file)\n",
        "            print(f\"Reading TSV file: {file}\")\n",
        "            try:\n",
        "                # Read the TSV file into a DataFrame\n",
        "                df = spark.read.csv(file_path, header=True, inferSchema=True, sep='\\t')\n",
        "\n",
        "                # Display the first 4 records\n",
        "                df.show(4)\n",
        "\n",
        "                # Stop after processing the first file\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file format: {file}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    # Keep spark session going\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "289mf8osuj0O"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "df = df.withColumn(\"review_body\", df[\"review_body\"].cast(\"string\"))\n",
        "df_clean = df.filter(df['review_body'].isNotNull() & (df['review_body'] != '')) # drop nulls\n",
        "\n",
        "# Tokenization and Cleaning\n",
        "regex_tokenizer = RegexTokenizer(inputCol=\"review_body\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "words_data = regex_tokenizer.transform(df_clean)\n",
        "\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "filtered_data = remover.transform(words_data)\n",
        "\n",
        "vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"raw_features\")\n",
        "vectorized_model = vectorizer.fit(filtered_data)\n",
        "vectorized_data = vectorized_model.transform(filtered_data)\n",
        "\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "idf_model = idf.fit(vectorized_data)\n",
        "final_data = idf_model.transform(vectorized_data)\n",
        "\n",
        "# Filtering\n",
        "low_ratings = final_data[(final_data['star_rating'] == 1) | (final_data['star_rating'] == 2)]\n",
        "high_ratings = final_data[(final_data['star_rating'] == 4) | (final_data['star_rating'] == 5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LL0j726J8Wv",
        "outputId": "6896ebe3-6780-4eba-ef16-59a360fd8e1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Icf36WVsu8f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3420028-ebe4-480e-f3d4-89e7a81c6d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Text Analysis and Processing\n",
        "\n",
        "# VADER Sentiment Analysis setup\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function for sentiment score\n",
        "def get_sentiment(text):\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    return sentiment['compound']\n",
        "\n",
        "# Function to categorize sentiment based on score\n",
        "def categorize_sentiment(score):\n",
        "    if score > 0.05:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Register the UDF\n",
        "sentiment_score_udf = udf(get_sentiment, StringType())\n",
        "sentiment_label_udf = udf(categorize_sentiment, StringType())\n",
        "\n",
        "# Apply VADER to low_ratings df\n",
        "low_ratings = low_ratings.withColumn(\"sentiment_score\", sentiment_score_udf(low_ratings[\"review_body\"]))\n",
        "low_ratings = low_ratings.withColumn(\"sentiment\", sentiment_label_udf(low_ratings[\"sentiment_score\"]))\n",
        "\n",
        "# Apply VADER to high_ratings df\n",
        "high_ratings = high_ratings.withColumn(\"sentiment_score\", sentiment_score_udf(high_ratings[\"review_body\"]))\n",
        "high_ratings = high_ratings.withColumn(\"sentiment\", sentiment_label_udf(high_ratings[\"sentiment_score\"]))\n",
        "\n",
        "# Key Phrase Extraaction\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "low_ratings = low_ratings.withColumn(\"keywords\", F.array_distinct(F.col(\"filtered\")))\n",
        "high_ratings = high_ratings.withColumn(\"keywords\", F.array_distinct(F.col(\"filtered\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIDI_53R6_I1",
        "outputId": "4a70fe95-1ac3-4ad1-e12b-b2fdabc86ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving summarized dataset...\n",
            "\n",
            "=== Summarized Dataset Sample ===\n",
            "+----------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+-----------+-------------+\n",
            "|product_category|sentiment|key_phrases                                                                                                                                                                                         |summarized_feedback                                                                                                                |star_rating|helpful_votes|\n",
            "+----------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+-----------+-------------+\n",
            "|Major Appliances|Negative |cool, 55, degrees, stopped, working, together, recommend, piece, junk, anyone                                                                                                                       |It would not cool below 55 degrees and has now stopped working all together.   I would NOT recommend this piece of junk to anyone. |1          |0            |\n",
            "|Major Appliances|Positive |worth, 22, dollars, ve, heard, became, value, high                                                                                                                                                  |it's not worth 22 dollars, I've heard it became of some value just not that high.                                                  |2          |0            |\n",
            "|Major Appliances|Positive |cheap, knock, dont, waste, time                                                                                                                                                                     |cheap knock-off.  dont waste your time                                                                                             |1          |0            |\n",
            "|Major Appliances|Negative |3, buttons, stopped, working, month, using, used, twice, day, recommend, go, use, money, something, durable, oh, also, big, plates, fit                                                             |3 of the buttons stopped working after a month of using it.  It was used twice a day.  Do not recommend it                         |1          |0            |\n",
            "|Major Appliances|Negative |buy, recently, purchased, water, leaks, bottom, veggie, tray, ice, formation, also, bad, design, ill, calling, lg, wasting, time, trying, get, repaired, really, expensive, refrigerator, stay, away|Do not buy.   Recently purchased, water leaks under bottom veggie tray, ice formation also.   Bad design                           |1          |10           |\n",
            "+----------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "=== Category Statistics ===\n",
            "+----------------+-------------+------------------+-------------------+\n",
            "|product_category|total_reviews|avg_rating        |positive_percentage|\n",
            "+----------------+-------------+------------------+-------------------+\n",
            "|Major Appliances|90171        |3.7697264087123354|0.7302015060274367 |\n",
            "+----------------+-------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Summarization\n",
        "def create_summarized_dataset(df):\n",
        "    summarized = df.select(\n",
        "        \"product_category\",\n",
        "        \"sentiment\",\n",
        "        F.array_join(\"keywords\", \", \").alias(\"key_phrases\"),\n",
        "        F.array_join(F.slice(F.split(F.col(\"review_body\"), \"[.!?]\"), 1, 3), \". \").alias(\"summarized_feedback\"),\n",
        "        \"star_rating\",\n",
        "        \"helpful_votes\"\n",
        "    )\n",
        "    return summarized\n",
        "\n",
        "# Combine ratings and create summary\n",
        "combined_ratings = low_ratings.union(high_ratings)\n",
        "summarized_data = create_summarized_dataset(combined_ratings)\n",
        "\n",
        "# Save as CSV\n",
        "print(\"Saving summarized dataset...\")\n",
        "summarized_data.write.mode(\"overwrite\") \\\n",
        "   .option(\"header\", \"true\") \\\n",
        "   .csv(\"amazon_reviews_summarized.csv\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\n=== Summarized Dataset Sample ===\")\n",
        "summarized_data.show(5, truncate=False)\n",
        "\n",
        "# Calculate category-level statistics\n",
        "category_stats = summarized_data.groupBy(\"product_category\") \\\n",
        "   .agg(\n",
        "       F.count(\"*\").alias(\"total_reviews\"),\n",
        "       F.avg(\"star_rating\").alias(\"avg_rating\"),\n",
        "       F.avg(F.when(F.col(\"sentiment\") == \"Positive\", 1).otherwise(0)).alias(\"positive_percentage\")\n",
        "   )\n",
        "\n",
        "print(\"\\n=== Category Statistics ===\")\n",
        "category_stats.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final_data.withColumn(\n",
        "    \"sentiment\",\n",
        "    F.when(F.col(\"star_rating\") >= 4, \"Positive\")\n",
        "    .when(F.col(\"star_rating\") <= 2, \"Negative\")\n",
        "    .otherwise(\"Neutral\")\n",
        ")\n",
        "\n",
        "print(\"Sample of data with sentiment:\")\n",
        "final_data.select(\"star_rating\", \"sentiment\").show(5)\n",
        "\n",
        "# Check available columns\n",
        "print(\"\\nAvailable columns:\")\n",
        "print(final_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB9MNVj-eHdt",
        "outputId": "3cf0a2ac-20d5-4ba4-bc07-d0099e953588"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of data with sentiment:\n",
            "+-----------+---------+\n",
            "|star_rating|sentiment|\n",
            "+-----------+---------+\n",
            "|          5| Positive|\n",
            "|          5| Positive|\n",
            "|          5| Positive|\n",
            "|          5| Positive|\n",
            "|          5| Positive|\n",
            "+-----------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Available columns:\n",
            "['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date', 'words', 'filtered', 'raw_features', 'features', 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8BlMTtWUwV4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c573a5c-9dee-468b-9caa-d9285125b93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: Major Appliances\n"
          ]
        }
      ],
      "source": [
        "def analyze_category_patterns(df, category):\n",
        "    \"\"\"Analyze specific patterns and issues for a given category\"\"\"\n",
        "    category_data = df.filter(F.col(\"product_category\") == category)\n",
        "\n",
        "    # Negative issues analysis\n",
        "    issues = category_data.filter(F.col(\"sentiment\") == \"Negative\")\\\n",
        "        .select(F.explode(\"filtered\").alias(\"issue\"))\\\n",
        "        .groupBy(\"issue\")\\\n",
        "        .count()\\\n",
        "        .orderBy(F.desc(\"count\"))\\\n",
        "        .limit(5)\n",
        "\n",
        "    # Positive highlights analysis\n",
        "    highlights = category_data.filter(F.col(\"sentiment\") == \"Positive\")\\\n",
        "        .select(F.explode(\"filtered\").alias(\"highlight\"))\\\n",
        "        .groupBy(\"highlight\")\\\n",
        "        .count()\\\n",
        "        .orderBy(F.desc(\"count\"))\\\n",
        "        .limit(5)\n",
        "\n",
        "    return issues, highlights\n",
        "\n",
        "# Analyze patterns for each category\n",
        "categories = final_data.select(\"product_category\").distinct().collect()\n",
        "category_insights = {}\n",
        "\n",
        "for row in categories:\n",
        "    category = row[\"product_category\"]\n",
        "    print(f\"Processing category: {category}\")\n",
        "    issues, highlights = analyze_category_patterns(final_data, category)\n",
        "    category_insights[category] = {\n",
        "        \"top_issues\": issues.collect(),\n",
        "        \"top_highlights\": highlights.collect()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DFYRs1uavERY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd93ac9e-ea8b-461d-ffe3-9990a76f2f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Overall Statistics ===\n",
            "+-----------------+------------------+-------------------+-----------------+\n",
            "|   average_rating|     rating_stddev|total_helpful_votes|avg_helpful_votes|\n",
            "+-----------------+------------------+-------------------+-----------------+\n",
            "|3.716363223515812|1.6033305005192597|             420499|4.340052431673685|\n",
            "+-----------------+------------------+-------------------+-----------------+\n",
            "\n",
            "\n",
            "=== Sentiment Distribution ===\n",
            "+---------+-----+----------+\n",
            "|sentiment|count|percentage|\n",
            "+---------+-----+----------+\n",
            "| Positive|64858|     66.94|\n",
            "|  Neutral| 6717|      6.93|\n",
            "| Negative|25313|     26.13|\n",
            "+---------+-----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aggregation and Insights\n",
        "total_reviews = final_data.count()\n",
        "\n",
        "statistics = final_data.agg(\n",
        "    F.avg(\"star_rating\").alias(\"average_rating\"),\n",
        "    F.stddev(\"star_rating\").alias(\"rating_stddev\"),\n",
        "    F.sum(\"helpful_votes\").alias(\"total_helpful_votes\"),\n",
        "    F.avg(\"helpful_votes\").alias(\"avg_helpful_votes\")\n",
        ")\n",
        "\n",
        "# Sentiment distribution\n",
        "sentiment_dist = final_data.groupBy(\"sentiment\") \\\n",
        "    .agg(F.count(\"*\").alias(\"count\")) \\\n",
        "    .withColumn(\"percentage\", F.round(F.col(\"count\") / total_reviews * 100, 2))\n",
        "\n",
        "print(\"=== Overall Statistics ===\")\n",
        "statistics.show()\n",
        "\n",
        "print(\"\\n=== Sentiment Distribution ===\")\n",
        "sentiment_dist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Brt8zaX_wclI"
      },
      "outputs": [],
      "source": [
        "# First, create the summarized data\n",
        "summarized_data = final_data.groupBy(\"product_category\", \"sentiment\")\\\n",
        "    .agg(\n",
        "        F.count(\"*\").alias(\"review_count\"),\n",
        "        F.avg(\"star_rating\").alias(\"avg_rating\"),\n",
        "        F.avg(\"helpful_votes\").alias(\"avg_helpful_votes\")\n",
        "    )\n",
        "\n",
        "def generate_insights_report(summarized_data, category_insights):\n",
        "    \"\"\"Generate a comprehensive insights report with proper formatting of metrics\"\"\"\n",
        "    report = \"\"\"Customer Feedback Analysis Report\n",
        "===============================\n",
        "\n",
        "Overall Statistics:\"\"\"\n",
        "\n",
        "    # Overall statistics\n",
        "    total_reviews = summarized_data.agg(F.sum(\"review_count\")).collect()[0][0]\n",
        "    avg_rating = summarized_data.agg(F.avg(\"avg_rating\")).collect()[0][0]\n",
        "\n",
        "    report += f\"\"\"\n",
        "\n",
        "Total Reviews Analyzed: {total_reviews:,}\n",
        "Average Rating: {avg_rating:.2f}\n",
        "\n",
        "Key Findings by Category:\"\"\"\n",
        "\n",
        "    # Category-specific insights\n",
        "    for category in category_insights.keys():\n",
        "        report += f\"\\n\\n{category}:\"\n",
        "\n",
        "        # Get sentiment distribution for this category\n",
        "        category_data = summarized_data.filter(F.col(\"product_category\") == category)\n",
        "        total_category_reviews = category_data.agg(F.sum(\"review_count\")).collect()[0][0]\n",
        "\n",
        "        report += f\"\\nTotal Reviews: {total_category_reviews:,}\"\n",
        "\n",
        "        report += \"\\n  Top Issues:\"\n",
        "        for issue in category_insights[category][\"top_issues\"]:\n",
        "            # Properly access the count value\n",
        "            report += f\"\\n    - {issue['issue']}: {issue['count']:,} mentions ({(issue['count']/total_category_reviews*100):.1f}%)\"\n",
        "\n",
        "        report += \"\\n  Top Highlights:\"\n",
        "        for highlight in category_insights[category][\"top_highlights\"]:\n",
        "            # Properly access the count value\n",
        "            report += f\"\\n    - {highlight['highlight']}: {highlight['count']:,} mentions ({(highlight['count']/total_category_reviews*100):.1f}%)\"\n",
        "\n",
        "    report += \"\"\"\n",
        "\n",
        "Analysis Summary:\n",
        "----------------\n",
        "1. Review Volume Analysis:\n",
        "   - Identified categories with highest review counts\n",
        "   - Tracked review distribution across sentiment categories\n",
        "\n",
        "2. Sentiment Patterns:\n",
        "   - Analyzed positive vs negative sentiment ratios\n",
        "   - Identified common themes in positive and negative feedback\n",
        "\n",
        "3. Key Issues Identified:\n",
        "   - Documented most frequent customer complaints\n",
        "   - Tracked recurring product-specific concerns\n",
        "\n",
        "4. Success Factors:\n",
        "   - Highlighted features receiving positive feedback\n",
        "   - Identified strongest product attributes\n",
        "\n",
        "Actionable Recommendations:\n",
        "-------------------------\n",
        "1. Product Improvements:\n",
        "   - Address frequently mentioned issues in each category\n",
        "   - Focus on recurring technical or quality concerns\n",
        "\n",
        "2. Marketing Opportunities:\n",
        "   - Leverage positive aspects identified in reviews\n",
        "   - Highlight well-received product features\n",
        "\n",
        "3. Category Focus:\n",
        "   - Prioritize categories with lower satisfaction scores\n",
        "   - Implement targeted improvements for underperforming products\n",
        "\n",
        "4. Monitoring Strategy:\n",
        "   - Continue tracking trending topics\n",
        "   - Establish regular review analysis schedule\n",
        "\n",
        "5. Customer Service:\n",
        "   - Address common service-related complaints\n",
        "   - Enhance support for frequently mentioned issues\n",
        "\"\"\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Function to analyze patterns with proper count handling\n",
        "def analyze_category_patterns(df, category):\n",
        "    \"\"\"Analyze specific patterns and issues for a given category with improved count handling\"\"\"\n",
        "    category_data = df.filter(F.col(\"product_category\") == category)\n",
        "\n",
        "    # Negative issues analysis\n",
        "    issues = category_data.filter(F.col(\"sentiment\") == \"Negative\")\\\n",
        "        .select(F.explode(\"filtered\").alias(\"issue\"))\\\n",
        "        .groupBy(\"issue\")\\\n",
        "        .count()\\\n",
        "        .orderBy(F.desc(\"count\"))\\\n",
        "        .limit(5)\\\n",
        "        .collect()  # Collect the results\n",
        "\n",
        "    # Positive highlights analysis\n",
        "    highlights = category_data.filter(F.col(\"sentiment\") == \"Positive\")\\\n",
        "        .select(F.explode(\"filtered\").alias(\"highlight\"))\\\n",
        "        .groupBy(\"highlight\")\\\n",
        "        .count()\\\n",
        "        .orderBy(F.desc(\"count\"))\\\n",
        "        .limit(5)\\\n",
        "        .collect()  # Collect the results\n",
        "\n",
        "    return issues, highlights\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and save report\n",
        "insights_report = generate_insights_report(summarized_data, category_insights)\n",
        "with open(\"customer_feedback_insights.txt\", \"w\", encoding='utf-8') as f:\n",
        "    f.write(insights_report)"
      ],
      "metadata": {
        "id": "K7ULds6MgIpk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lSwRWyZgK3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}